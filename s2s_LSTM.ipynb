{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "各種seq2seqモデルによる英→日の翻訳を行う。\n",
    "\n",
    "このノートブックはそのうちのLSTMを使ったもの。\n",
    "\n",
    "コーパスはYusuke Oda氏作成のsmall_parallel_enjaを使用します。\n",
    "https://github.com/odashi/small_parallel_enja\n",
    "\n",
    "処理の流れは以下の通り。\n",
    "\n",
    "* 前処理\n",
    "    1. 開始・終了トークンの付与\n",
    "    2. 単語IDへの変換則を定義\n",
    "    3. 文章を単語IDの列に変換。列の長さはコーパス内の最大の文章の長さに0埋めで揃える\n",
    "    4. teacher forcingのため、target側の単語列の単語の位置を一つずらしたものを新たに作成\n",
    "* モデルの定義\n",
    "    1. ハイパーパラメータの定義\n",
    "    2. encoderの定義\n",
    "    3. decorderの定義\n",
    "* 学習条件の定義と学習\n",
    "* 学習結果の保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの可視化のため、pydotをインストールする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/ec2-user/.local/lib/python3.6/site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pydot) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --user pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "終了後一度kernel restartする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8637183300087174387, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14140932922371192234\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 3607747149602401627\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11330115994\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16570887996260716394\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理\n",
    "通常、言語データを時系列データとして解析する際は、以下のようなステップをたどる\n",
    "1. 文字列の読み込み\n",
    "2. 単語単位への分解\n",
    "3. 単語へのID割り振り\n",
    "4. 単語列からIDの羅列への変換\n",
    "\n",
    "今回のデータセットは単語単位への分解がすでに終わっているので省略できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ユニコードファイルを ascii に変換\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # 文の開始と終了のトークンを付加\n",
    "    # モデルが予測をいつ開始し、いつ終了すれば良いかを知らせるため\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    with open(path) as f:\n",
    "        word_pairs = f.readlines()\n",
    "    word_pairs = [preprocess_sentence(sentence) for sentence in word_pairs]\n",
    "\n",
    "    return word_pairs[:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> he thought irritably . <end>\n",
      "<start> 彼 は いらだ ち ながら 思 っ た 。 <end>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# データの読み込み\n",
    "path_train_en = 'small_parallel_enja/train.en'\n",
    "path_train_ja = 'small_parallel_enja/train.ja'\n",
    "en = create_dataset(path_train_en, None)\n",
    "ja = create_dataset(path_train_ja, None)\n",
    "print(en[-1])\n",
    "print(ja[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    #これはなくす。\n",
    "    #学習済みw2vをembeddingにつかうので\n",
    "    lang_tokenizer = keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    # クリーニングされた入力と出力のペアを生成\n",
    "    lang = create_dataset(path, num_examples)\n",
    "\n",
    "    tensor, lang_tokenizer = tokenize(lang)\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語へのIDの割り振りとID列への変換\n",
    "# このサイズのデータセットで実験\n",
    "num_examples = None\n",
    "input_tensor, inp_lang = load_dataset(path_train_en, num_examples)\n",
    "target_tensor, targ_lang = load_dataset(path_train_ja, num_examples)\n",
    "# ターゲットテンソルの最大長を計算\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "2 ----> <start>\n",
      "6 ----> i\n",
      "42 ----> can\n",
      "20 ----> 't\n",
      "151 ----> tell\n",
      "137 ----> who\n",
      "30 ----> will\n",
      "727 ----> arrive\n",
      "234 ----> first\n",
      "4 ----> .\n",
      "3 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "92 ----> 誰\n",
      "14 ----> が\n",
      "230 ----> 一番\n",
      "7 ----> に\n",
      "155 ----> 着\n",
      "29 ----> く\n",
      "22 ----> か\n",
      "18 ----> 私\n",
      "7 ----> に\n",
      "5 ----> は\n",
      "277 ----> 分か\n",
      "38 ----> り\n",
      "21 ----> ま\n",
      "41 ----> せ\n",
      "30 ----> ん\n",
      "4 ----> 。\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teacher forcingのため、decoder_input_tensor_train、decoder_target_tensor_trainを作っておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############データの加工がいる\n",
    "encoder_input_tensor = input_tensor\n",
    "decoder_input_tensor = target_tensor[:,:-1]\n",
    "decoder_target_tensor = target_tensor[:,1:] #これでteacher forcingを実現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor)\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "steps_per_epoch = len(input_tensor)//batch_size\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoderの定義\n",
    "1. 入力された単語IDをembedding\n",
    "2. LSTMでhidden stateに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(max_length_inp,),name='encoder_input')\n",
    "encoder_inputs_embedding = Embedding(input_dim=vocab_inp_size, output_dim=embedding_dim)(encoder_inputs)\n",
    "encoder = LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_embedding)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoderの定義\n",
    "1. 入力（decoder_input_tensor_trainを想定）をembedding\n",
    "2. embeddingとencoderのstate_h, state_cをLSTMに入力\n",
    "3. outputをDense+softmaxで単語ごとの確率に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(max_length_targ-1,),name='decoder_input')\n",
    "decoder_inputs_embedding  = Embedding(input_dim=vocab_tar_size, output_dim=embedding_dim)(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_embedding,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_tar_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記を使ってモデルを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 348.00 337.00\" width=\"348pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 344,-333 344,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140516834698800 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140516834698800</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 161,-328.5 161,-292.5 0,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-306.8\">encoder_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140517812438800 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140517812438800</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 161,-255.5 161,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-233.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 140516834698800&#45;&gt;140517812438800 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140516834698800-&gt;140517812438800</title>\n",
       "<path d=\"M80.5,-292.4551C80.5,-284.3828 80.5,-274.6764 80.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"84.0001,-265.5903 80.5,-255.5904 77.0001,-265.5904 84.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140515438023792 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140515438023792</title>\n",
       "<polygon fill=\"none\" points=\"179,-219.5 179,-255.5 340,-255.5 340,-219.5 179,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-233.8\">decoder_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140515450310216 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140515450310216</title>\n",
       "<polygon fill=\"none\" points=\"171,-146.5 171,-182.5 332,-182.5 332,-146.5 171,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"251.5\" y=\"-160.8\">embedding_2: Embedding</text>\n",
       "</g>\n",
       "<!-- 140515438023792&#45;&gt;140515450310216 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140515438023792-&gt;140515450310216</title>\n",
       "<path d=\"M257.5225,-219.4551C256.6378,-211.3828 255.5741,-201.6764 254.5884,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"258.0511,-192.1495 253.4825,-182.5904 251.0928,-192.9122 258.0511,-192.1495\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140517670731560 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140517670731560</title>\n",
       "<polygon fill=\"none\" points=\"46.5,-146.5 46.5,-182.5 144.5,-182.5 144.5,-146.5 46.5,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"95.5\" y=\"-160.8\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 140517812438800&#45;&gt;140517670731560 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140517812438800-&gt;140517670731560</title>\n",
       "<path d=\"M84.2079,-219.4551C85.8846,-211.2951 87.9044,-201.4652 89.7694,-192.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"93.1984,-193.0902 91.7828,-182.5904 86.3416,-191.6812 93.1984,-193.0902\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140515438023512 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140515438023512</title>\n",
       "<polygon fill=\"none\" points=\"120.5,-73.5 120.5,-109.5 218.5,-109.5 218.5,-73.5 120.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-87.8\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 140515450310216&#45;&gt;140515438023512 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140515450310216-&gt;140515438023512</title>\n",
       "<path d=\"M231.2303,-146.4551C221.0788,-137.4177 208.6262,-126.3319 197.5709,-116.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"199.617,-113.6255 189.8207,-109.5904 194.9625,-118.8539 199.617,-113.6255\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140517670731560&#45;&gt;140515438023512 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140517670731560-&gt;140515438023512</title>\n",
       "<path d=\"M113.7921,-146.4551C122.8644,-137.5054 133.9729,-126.547 143.8768,-116.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.5008,-119.1049 151.1618,-109.5904 141.5848,-114.1215 146.5008,-119.1049\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140515438026312 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140515438026312</title>\n",
       "<polygon fill=\"none\" points=\"118.5,-.5 118.5,-36.5 220.5,-36.5 220.5,-.5 118.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140515438023512&#45;&gt;140515438026312 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140515438023512-&gt;140515438026312</title>\n",
       "<path d=\"M169.5,-73.4551C169.5,-65.3828 169.5,-55.6764 169.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"173.0001,-46.5903 169.5,-36.5904 166.0001,-46.5904 173.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 18)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 18, 256)      1699328     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 17, 256)      2247168     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 1024), (None 5246976     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 17, 1024), ( 5246976     embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 17, 8778)     8997450     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,437,898\n",
      "Trainable params: 23,437,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習条件の定義と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "40000/40000 [==============================] - 130s 3ms/step - loss: 2.9959 - acc: 0.4776 - val_loss: 2.3314 - val_acc: 0.5695\n",
      "Epoch 2/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 2.1442 - acc: 0.5925 - val_loss: 2.0688 - val_acc: 0.6108\n",
      "Epoch 3/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 1.8858 - acc: 0.6325 - val_loss: 1.8788 - val_acc: 0.6422\n",
      "Epoch 4/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 1.6757 - acc: 0.6657 - val_loss: 1.7361 - val_acc: 0.6658\n",
      "Epoch 5/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 1.5032 - acc: 0.6896 - val_loss: 1.6239 - val_acc: 0.6824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_4:0' shape=(?, 1024) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 1.3458 - acc: 0.7114 - val_loss: 1.5374 - val_acc: 0.6959\n",
      "Epoch 2/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 1.2036 - acc: 0.7309 - val_loss: 1.4635 - val_acc: 0.7075\n",
      "Epoch 3/5\n",
      "40000/40000 [==============================] - 128s 3ms/step - loss: 1.0745 - acc: 0.7508 - val_loss: 1.4086 - val_acc: 0.7173\n",
      "Epoch 4/5\n",
      "40000/40000 [==============================] - 128s 3ms/step - loss: 0.9585 - acc: 0.7711 - val_loss: 1.3684 - val_acc: 0.7238\n",
      "Epoch 5/5\n",
      "40000/40000 [==============================] - 128s 3ms/step - loss: 0.8542 - acc: 0.7913 - val_loss: 1.3468 - val_acc: 0.7283\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.7599 - acc: 0.8103 - val_loss: 1.3254 - val_acc: 0.7331\n",
      "Epoch 2/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.6741 - acc: 0.8294 - val_loss: 1.3172 - val_acc: 0.7360\n",
      "Epoch 3/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.5953 - acc: 0.8479 - val_loss: 1.3165 - val_acc: 0.7384\n",
      "Epoch 4/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.5222 - acc: 0.8662 - val_loss: 1.3241 - val_acc: 0.7393\n",
      "Epoch 5/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.4537 - acc: 0.8845 - val_loss: 1.3374 - val_acc: 0.7388\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.3914 - acc: 0.9011 - val_loss: 1.3524 - val_acc: 0.7405\n",
      "Epoch 2/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.3342 - acc: 0.9170 - val_loss: 1.3807 - val_acc: 0.7395\n",
      "Epoch 3/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.2817 - acc: 0.9321 - val_loss: 1.4021 - val_acc: 0.7391\n",
      "Epoch 4/5\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 0.2361 - acc: 0.9451 - val_loss: 1.4342 - val_acc: 0.7386\n",
      "Epoch 5/5\n",
      "40000/40000 [==============================] - 128s 3ms/step - loss: 0.1956 - acc: 0.9569 - val_loss: 1.4634 - val_acc: 0.7378\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# define save condition\n",
    "dir_path = 'saved_models/LSTM/'\n",
    "save_every = 5\n",
    "train_schedule = [save_every for i in range(divmod(epochs,save_every)[0])]\n",
    "if divmod(epochs,save_every)[1] != 0:\n",
    "    train_schedule += [divmod(epochs,save_every)[1]]\n",
    "    \n",
    "#run training\n",
    "total_epochs = 0\n",
    "for epoch in train_schedule:\n",
    "    history = model.fit([encoder_input_tensor, decoder_input_tensor], \n",
    "                          np.apply_along_axis(lambda x: np_utils.to_categorical(x,num_classes=vocab_tar_size), 1, decoder_target_tensor),\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epoch,\n",
    "                          validation_split=0.2)\n",
    "    total_epochs += epoch\n",
    "    filename = str(total_epochs) + 'epochs_LSTM.h5'\n",
    "    model.save(dir_path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(dir_path+str(total_epochs)+'epochs_LSTM.history', 'w') as file_pi:\n",
    "    json.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
